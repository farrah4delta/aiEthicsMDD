"""Model client wrapper module."""
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Tuple

try:
    import requests
except ImportError:
    requests = None

from openai import OpenAI
from openai.types.chat import ChatCompletion

from aiei_l4.config import Settings


class BaseModelClient(ABC):
    """Abstract base class for model clients."""

    def __init__(self, model_name: str):
        self.model_name = model_name

    @abstractmethod
    def generate(self, messages: List[Dict[str, str]]) -> str:
        """
        Generate a response.

        Args:
            messages: Message list in format [{"role": "system", "content": "..."}, ...]

        Returns:
            Text response generated by the model
        """
        pass


class OpenAIChatClient(BaseModelClient):
    """OpenAI Chat Completions API client."""

    def __init__(self, model_name: str, api_key: str, temperature: float = 0.2):
        super().__init__(model_name)
        self.client = OpenAI(api_key=api_key)
        self.temperature = temperature

    def generate(self, messages: List[Dict[str, str]]) -> str:
        """Call OpenAI Chat Completions API."""
        try:
            response: ChatCompletion = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,  # type: ignore
                temperature=self.temperature,
            )
            return response.choices[0].message.content or ""
        except Exception as e:
            raise RuntimeError(f"Model call failed: {e}") from e


class GeminiChatClient(BaseModelClient):
    """Google Gemini API client (using REST API, compatible with Python 3.8)."""

    def __init__(self, model_name: str, api_key: str, temperature: float = 0.2):
        super().__init__(model_name)
        if requests is None:
            raise ImportError(
                "requests is not installed. Please run: pip install requests"
            )
        self.api_key = api_key
        self.temperature = temperature
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"

    def generate(self, messages: List[Dict[str, str]]) -> str:
        """Call Gemini API (using REST API, compatible with Python 3.8)."""
        try:
            # Extract system message and user messages
            system_content = ""
            user_parts = []
            
            for msg in messages:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "system":
                    system_content = content
                elif role == "user":
                    user_parts.append({"text": content})
                elif role == "assistant":
                    user_parts.append({"text": content})

            # Build request content
            contents = []
            if system_content:
                # Gemini REST API supports systemInstruction
                system_instruction = {"parts": [{"text": system_content}]}
            else:
                system_instruction = None
            
            # Add user messages
            if user_parts:
                contents.append({"parts": user_parts})

            # Try different model name formats
            clean_model_name = self.model_name.replace('models/', '')
            model_names_to_try = [
                clean_model_name,  # gemini-2.5-flash
                clean_model_name.replace('1.5', '2.5'),  # Try upgrading to 2.5
                clean_model_name.replace('2.5', '1.5'),  # Try downgrading to 1.5
                'gemini-2.5-flash',
                'gemini-2.5-pro',
                'gemini-1.5-flash',
                'gemini-1.5-pro',
                'gemini-pro',
            ]
            
            last_error = None
            for model_name in model_names_to_try:
                try:
                    # Build REST API request
                    url = f"{self.base_url}/models/{model_name}:generateContent"
                    headers = {
                        "Content-Type": "application/json",
                        "x-goog-api-key": self.api_key,
                    }
                    
                    payload = {
                        "contents": contents,
                        "generationConfig": {
                            "temperature": self.temperature,
                        }
                    }
                    
                    # If there's a system instruction, add it to the request
                    if system_instruction:
                        payload["systemInstruction"] = system_instruction
                    
                    response = requests.post(url, headers=headers, json=payload, timeout=60)
                    response.raise_for_status()
                    
                    result = response.json()
                    
                    # Parse response
                    if "candidates" in result and len(result["candidates"]) > 0:
                        candidate = result["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            text_parts = [
                                part.get("text", "")
                                for part in candidate["content"]["parts"]
                                if "text" in part
                            ]
                            return "".join(text_parts)
                    
                    # If text not found, try other formats
                    if "text" in result:
                        return result["text"]
                    
                    raise ValueError(f"Unable to extract text from response: {result}")
                    
                except requests.exceptions.HTTPError as e:
                    if e.response.status_code == 404:
                        # Model doesn't exist, try next one
                        last_error = e
                        continue
                    else:
                        # Other HTTP errors, raise directly
                        raise RuntimeError(f"HTTP error {e.response.status_code}: {e.response.text}") from e
                except Exception as e:
                    last_error = e
                    continue
            
            # All attempts failed
            raise RuntimeError(f"All model name attempts failed. Last error: {last_error}")
        except Exception as e:
            raise RuntimeError(f"Gemini model call failed: {e}") from e


class DummyModelClient(BaseModelClient):
    """Dummy model client for testing."""

    def __init__(self, model_name: str, fixed_response: str = "This is a test response."):
        super().__init__(model_name)
        self.fixed_response = fixed_response

    def generate(self, messages: List[Dict[str, str]]) -> str:
        """Return a fixed test response."""
        return self.fixed_response


def get_model_clients(settings: Settings) -> Tuple[BaseModelClient, BaseModelClient]:
    """
    Create two model clients.

    Args:
        settings: Configuration object

    Returns:
        Tuple of (model_a_client, model_b_client)
    """
    # Determine the provider for each model
    provider_a = (settings.model_a_provider or settings.api_provider).lower()
    provider_b = (settings.model_b_provider or settings.api_provider).lower()

    # Create model A client
    if provider_a == "gemini":
        if not settings.gemini_api_key:
            raise ValueError("GEMINI_API_KEY must be set when using Gemini")
        client_a = GeminiChatClient(
            model_name=settings.model_a_name,
            api_key=settings.gemini_api_key,
            temperature=settings.temperature,
        )
    elif provider_a == "openai":
        if not settings.openai_api_key:
            raise ValueError("OPENAI_API_KEY must be set when using OpenAI")
        client_a = OpenAIChatClient(
            model_name=settings.model_a_name,
            api_key=settings.openai_api_key,
            temperature=settings.temperature,
        )
    else:
        raise ValueError(f"Unsupported API provider (Model A): {provider_a}. Supported: 'openai' or 'gemini'")

    # Create model B client
    if provider_b == "gemini":
        if not settings.gemini_api_key:
            raise ValueError("GEMINI_API_KEY must be set when using Gemini")
        client_b = GeminiChatClient(
            model_name=settings.model_b_name,
            api_key=settings.gemini_api_key,
            temperature=settings.temperature,
        )
    elif provider_b == "openai":
        if not settings.openai_api_key:
            raise ValueError("OPENAI_API_KEY must be set when using OpenAI")
        client_b = OpenAIChatClient(
            model_name=settings.model_b_name,
            api_key=settings.openai_api_key,
            temperature=settings.temperature,
        )
    else:
        raise ValueError(f"Unsupported API provider (Model B): {provider_b}. Supported: 'openai' or 'gemini'")

    return client_a, client_b

